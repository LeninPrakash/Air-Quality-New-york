{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8331248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a23545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('Air_Quality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b77eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['Time Period'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b85d4",
   "metadata": {},
   "source": [
    "EDA Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698c194a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique ID           int64\n",
       "Indicator ID        int64\n",
       "Name               object\n",
       "Measure            object\n",
       "Measure Info       object\n",
       "Geo Type Name      object\n",
       "Geo Join ID         int64\n",
       "Geo Place Name     object\n",
       "Start_Date         object\n",
       "Data Value        float64\n",
       "Message           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071add2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories in the \"Name\" column are:\n",
      "['Nitrogen dioxide (NO2)' 'Fine particles (PM 2.5)' 'Ozone (O3)'\n",
      " 'Asthma emergency department visits due to PM2.5'\n",
      " 'Annual vehicle miles traveled' 'Asthma hospitalizations due to Ozone'\n",
      " 'Respiratory hospitalizations due to PM2.5 (age 20+)'\n",
      " 'Boiler Emissions- Total SO2 Emissions'\n",
      " 'Cardiovascular hospitalizations due to PM2.5 (age 40+)'\n",
      " 'Boiler Emissions- Total PM2.5 Emissions'\n",
      " 'Boiler Emissions- Total NOx Emissions'\n",
      " 'Annual vehicle miles travelled (cars)'\n",
      " 'Annual vehicle miles travelled (trucks)'\n",
      " 'Cardiac and respiratory deaths due to Ozone'\n",
      " 'Asthma emergency departments visits due to Ozone'\n",
      " 'Outdoor Air Toxics - Formaldehyde' 'Outdoor Air Toxics - Benzene'\n",
      " 'Deaths due to PM2.5']\n"
     ]
    }
   ],
   "source": [
    "unique_categories = df['Name'].unique()\n",
    "print(f'Unique categories in the \"Name\" column are:\\n{unique_categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c624bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+-----------+-----------+----------------------+\n",
      "|                          Name                          | Min Value | Max Value |         Unit         |\n",
      "+--------------------------------------------------------+-----------+-----------+----------------------+\n",
      "|             Annual vehicle miles traveled              |    4.9    |   86.0    |       per km2        |\n",
      "|         Annual vehicle miles travelled (cars)          |    4.7    |   80.8    |       per km2        |\n",
      "|        Annual vehicle miles travelled (trucks)         |    0.2    |    5.0    |       per km2        |\n",
      "|    Asthma emergency department visits due to PM2.5     |    4.9    |   424.7   | per 100,000 children |\n",
      "|    Asthma emergency departments visits due to Ozone    |    7.0    |   292.5   |  per 100,000 adults  |\n",
      "|          Asthma hospitalizations due to Ozone          |    0.6    |   57.8    |  per 100,000 adults  |\n",
      "|         Boiler Emissions- Total NOx Emissions          |    2.0    |   284.7   |        number        |\n",
      "|        Boiler Emissions- Total PM2.5 Emissions         |    0.0    |   11.4    |        number        |\n",
      "|         Boiler Emissions- Total SO2 Emissions          |    0.0    |   99.7    |        number        |\n",
      "|      Cardiac and respiratory deaths due to Ozone       |    2.4    |   11.7    |     per 100,000      |\n",
      "| Cardiovascular hospitalizations due to PM2.5 (age 40+) |   7.29    |   39.0    |  per 100,000 adults  |\n",
      "|                  Deaths due to PM2.5                   |   25.5    |   117.7   |  per 100,000 adults  |\n",
      "|                Fine particles (PM 2.5)                 |   5.32    |   18.84   |        mcg/m3        |\n",
      "|                 Nitrogen dioxide (NO2)                 |   4.85    |   50.56   |         ppb          |\n",
      "|              Outdoor Air Toxics - Benzene              |   0.57    |    6.3    |        µg/m3         |\n",
      "|           Outdoor Air Toxics - Formaldehyde            |   1.09    |    5.3    |        µg/m3         |\n",
      "|                       Ozone (O3)                       |   14.38   |   40.4    |         ppb          |\n",
      "|  Respiratory hospitalizations due to PM2.5 (age 20+)   |    4.7    |   44.8    |  per 100,000 adults  |\n",
      "+--------------------------------------------------------+-----------+-----------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Data Value' and 'Measure Info' are the columns for which you want to find max and min values\n",
    "result = df.groupby('Name').agg({'Data Value': ['min', 'max'], 'Measure Info': 'first'})\n",
    "\n",
    "# Rename the columns for clarity\n",
    "result.columns = ['Min Value', 'Max Value', 'Unit']\n",
    "\n",
    "# Print the result as a formatted table\n",
    "table = tabulate(result.reset_index(), headers=['Name', 'Min Value', 'Max Value', 'Unit'], tablefmt='pretty', showindex=False)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b07710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode 'Geo Type Name encoded' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Geo Type Name encoded'] = label_encoder.fit_transform(df['Geo Type Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359bc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Measure Info' and normalize 'Data Value' within each group\n",
    "scaler = MinMaxScaler()\n",
    "df['Normalized_Data_Value'] = df.groupby('Measure Info')['Data Value'].transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd2aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = df.groupby('Name')['Data Value'].max()\n",
    "\n",
    "# Define the risk thresholds\n",
    "low_threshold = 0.3\n",
    "medium_threshold = 0.6\n",
    "\n",
    "df['Message'] = pd.cut(df['Normalized_Data_Value'], bins=[-np.inf, low_threshold, medium_threshold, np.inf], labels=['Low Risk', 'Medium Risk', 'High Risk'])\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv('E:/Data Science/Air Quality/Air_Quality.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738b8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode 'Name' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Name'] = label_encoder.fit_transform(df['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8befec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Unique ID' as index\n",
    "df.set_index('Unique ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e78db4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Start_Date' to datetime\n",
    "df['Start_Date'] = pd.to_datetime(df['Start_Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf56e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Measure Info' column and perform label encoding\n",
    "measure_info_column = df['Measure Info']\n",
    "label_encoder = LabelEncoder()\n",
    "df['Measure Info Encoded'] = label_encoder.fit_transform(measure_info_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c93eab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure Info: mcg/m3\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "173129                  0.368343\n",
      "669692                  0.122781\n",
      "212069                  0.275148\n",
      "547517                  0.206361\n",
      "173125                  0.449704\n",
      "...                          ...\n",
      "669829                  0.059172\n",
      "179657                  0.304734\n",
      "168400                  0.690089\n",
      "213760                  0.625000\n",
      "211409                  0.477811\n",
      "\n",
      "[5499 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: number\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "179789                  0.004215\n",
      "130443                  0.007727\n",
      "179793                  0.005971\n",
      "179807                  0.145767\n",
      "179792                  0.003864\n",
      "...                          ...\n",
      "130414                  0.001054\n",
      "179783                  0.009835\n",
      "179813                  0.000351\n",
      "130400                  0.015455\n",
      "130444                  0.000351\n",
      "\n",
      "[288 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: per 100,000\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "518704                  0.204301\n",
      "629165                  0.086022\n",
      "151423                  0.784946\n",
      "151415                  0.333333\n",
      "151401                  0.086022\n",
      "...                          ...\n",
      "131010                  0.258065\n",
      "131000                  0.193548\n",
      "130996                  0.172043\n",
      "131020                  0.548387\n",
      "131026                  0.580645\n",
      "\n",
      "[192 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: per 100,000 adults\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "131372                  0.452938\n",
      "131374                  0.164357\n",
      "131228                  0.543717\n",
      "131221                  0.514095\n",
      "518945                  0.432776\n",
      "...                          ...\n",
      "130376                  0.281414\n",
      "130396                  0.307692\n",
      "518791                  0.062112\n",
      "628484                  0.096512\n",
      "131266                  0.138557\n",
      "\n",
      "[1152 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: per 100,000 children\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "518895                  0.099291\n",
      "628444                  0.061200\n",
      "518888                  0.190926\n",
      "518906                  0.260161\n",
      "518926                  0.199527\n",
      "...                          ...\n",
      "131170                  0.024102\n",
      "131458                  0.115784\n",
      "518887                  0.103804\n",
      "628436                  0.074669\n",
      "130834                  0.127127\n",
      "\n",
      "[576 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: per km2\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "325209                  0.301865\n",
      "151625                  0.275058\n",
      "325202                  0.421911\n",
      "325244                  0.621212\n",
      "154577                  0.439394\n",
      "...                          ...\n",
      "325182                  0.010490\n",
      "325101                  0.006993\n",
      "325197                  0.110723\n",
      "151626                  0.263403\n",
      "325247                  0.580420\n",
      "\n",
      "[632 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: ppb\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "172653                  0.447386\n",
      "172585                  0.483045\n",
      "336637                  0.311529\n",
      "336622                  0.326187\n",
      "172582                  0.393349\n",
      "...                          ...\n",
      "179272                  0.367097\n",
      "602701                  0.307810\n",
      "221842                  0.563334\n",
      "171567                  0.553927\n",
      "211560                  0.499453\n",
      "\n",
      "[7473 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Measure Info: µg/m3\n",
      "Min Normalized Data Value: 0.00\n",
      "Max Normalized Data Value: 1.00\n",
      "Normalized Data Values:\n",
      "           Normalized_Data_Value\n",
      "Unique ID                       \n",
      "130768                  0.319372\n",
      "130767                  0.319372\n",
      "315672                  0.232112\n",
      "799821                  0.202443\n",
      "799849                  0.129145\n",
      "...                          ...\n",
      "799836                  0.181501\n",
      "799818                  0.181501\n",
      "315637                  0.214660\n",
      "130750                  0.441536\n",
      "130780                  0.301920\n",
      "\n",
      "[406 rows x 1 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Measure Info' and print normalized data values along with min and max\n",
    "grouped_data = df.groupby('Measure Info')\n",
    "\n",
    "for measure_info, group_data in grouped_data:\n",
    "    min_value = group_data['Normalized_Data_Value'].min()\n",
    "    max_value = group_data['Normalized_Data_Value'].max()\n",
    "\n",
    "    print(f\"Measure Info: {measure_info}\")\n",
    "    print(f\"Min Normalized Data Value: {min_value:.2f}\")\n",
    "    print(f\"Max Normalized Data Value: {max_value:.2f}\")\n",
    "    print(f\"Normalized Data Values:\")\n",
    "    print(group_data[['Normalized_Data_Value']])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8faa08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (Y)\n",
    "X = df[['Name', 'Measure Info Encoded', 'Geo Type Name encoded', 'Normalized_Data_Value']]\n",
    "Y = df['Message']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8036ec",
   "metadata": {},
   "source": [
    "Classification Model: KNN, Decision Tree, and Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96904558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value: 1\n",
      "Best Cross-Validation Accuracy: 0.9972250769895847\n",
      "\n",
      "KNN Accuracy with Best k: 1.00\n",
      "KNN Classification Report with Best k:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   High Risk       0.99      0.99      0.99       193\n",
      "    Low Risk       1.00      1.00      1.00      1552\n",
      " Medium Risk       1.00      1.00      1.00      1499\n",
      "\n",
      "    accuracy                           1.00      3244\n",
      "   macro avg       1.00      1.00      1.00      3244\n",
      "weighted avg       1.00      1.00      1.00      3244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a range of k values to try\n",
    "k_values = list(range(1, 25))\n",
    "\n",
    "# Create a parameter grid for GridSearchCV\n",
    "param_grid = {'n_neighbors': k_values}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Display the best k value and corresponding accuracy\n",
    "print(\"Best k value:\", grid_search.best_params_['n_neighbors'])\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train the KNN classifier with the best k value on the entire training set\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set with the best k value\n",
    "Y_pred_knn_best = best_knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the KNN classifier with the best k value\n",
    "accuracy_knn_best = accuracy_score(Y_test, Y_pred_knn_best)\n",
    "classification_report_str_knn_best = classification_report(Y_test, Y_pred_knn_best)\n",
    "\n",
    "# Display the results for KNN with the best k value\n",
    "print(f'\\nKNN Accuracy with Best k: {accuracy_knn_best:.2f}')\n",
    "print('KNN Classification Report with Best k:')\n",
    "print(classification_report_str_knn_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d54701ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Best Decision Tree Cross-Validation Accuracy: 1.0\n",
      "\n",
      "Decision Tree Accuracy: 1.00\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   High Risk       1.00      1.00      1.00       193\n",
      "    Low Risk       1.00      1.00      1.00      1552\n",
      " Medium Risk       1.00      1.00      1.00      1499\n",
      "\n",
      "    accuracy                           1.00      3244\n",
      "   macro avg       1.00      1.00      1.00      3244\n",
      "weighted avg       1.00      1.00      1.00      3244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation for Decision Tree\n",
    "param_grid_dt = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
    "grid_search_dt = GridSearchCV(decision_tree_classifier, param_grid_dt, cv=5, scoring='accuracy')\n",
    "grid_search_dt.fit(X_train, Y_train)\n",
    "\n",
    "# Display the best parameters and corresponding accuracy for Decision Tree\n",
    "print(\"Best Decision Tree Parameters:\", grid_search_dt.best_params_)\n",
    "print(\"Best Decision Tree Cross-Validation Accuracy:\", grid_search_dt.best_score_)\n",
    "\n",
    "# Train the Decision Tree classifier with the best parameters on the entire training set\n",
    "best_dt_classifier = grid_search_dt.best_estimator_\n",
    "best_dt_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set for Decision Tree\n",
    "Y_pred_dt = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the Decision Tree classifier\n",
    "accuracy_dt = accuracy_score(Y_test, Y_pred_dt)\n",
    "classification_report_str_dt = classification_report(Y_test, Y_pred_dt)\n",
    "\n",
    "# Display the results for Decision Tree\n",
    "print(f'\\nDecision Tree Accuracy: {accuracy_dt:.2f}')\n",
    "print('Decision Tree Classification Report:')\n",
    "print(classification_report_str_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4944a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "Mean CV Score for Random Forest: 1.0\n",
      "\n",
      "Random Forest Accuracy: 1.00\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   High Risk       1.00      1.00      1.00       193\n",
      "    Low Risk       1.00      1.00      1.00      1552\n",
      " Medium Risk       1.00      1.00      1.00      1499\n",
      "\n",
      "    accuracy                           1.00      3244\n",
      "   macro avg       1.00      1.00      1.00      3244\n",
      "weighted avg       1.00      1.00      1.00      3244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation for Random Forest\n",
    "cv_scores_rf = cross_val_score(random_forest_classifier, X_train, Y_train, cv=5)\n",
    "\n",
    "# Display cross-validation scores for Random Forest\n",
    "print(\"\\nRandom Forest Cross-Validation Scores:\", cv_scores_rf)\n",
    "print(\"Mean CV Score for Random Forest:\", cv_scores_rf.mean())\n",
    "\n",
    "# Train the Random Forest classifier on the entire training set\n",
    "random_forest_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set for Random Forest\n",
    "Y_pred_rf = random_forest_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the Random Forest classifier\n",
    "accuracy_rf = accuracy_score(Y_test, Y_pred_rf)\n",
    "classification_report_str_rf = classification_report(Y_test, Y_pred_rf)\n",
    "\n",
    "# Display the results for Random Forest\n",
    "print(f'\\nRandom Forest Accuracy: {accuracy_rf:.2f}')\n",
    "print('Random Forest Classification Report:')\n",
    "print(classification_report_str_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be6ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
